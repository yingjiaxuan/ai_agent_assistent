面向跨语言支持的提示设计和多层次记忆架构

Designing Prompts and Multi-Layered Memory Architecture Toward AI Agents for Cross-Lingual Support

摘要： 大型语言模型（LLM）在长对话和跨会话互动中由于上下文窗口有限面临显著的长期记忆挑战，没有长期记忆支撑时往往会遗忘信息，无法随交互持续学习，并且在长任务中目标容易偏离。特别地，在跨语言场景下，即使模型具备多语言能力，也难以将不同语言中的相关知识关联起来，表现出明显的跨语言知识迁移障碍。为此，本文提出了一种面向跨语言支持的提示设计与多层次记忆架构，通过在智能体中引入短期记忆（STM）、长期记忆（LTM）和用户画像（UP）三层记忆模块，协同LLM实现跨轮次、跨语言的一致对话支持。我们系统介绍了该架构的设计理念与实现细节，并基于LoCoMo长对话基准和自定义场景脚本进行实验评估。结果表明，多层记忆架构有效提升了人物信息记忆保留、用户偏好遵循和多轮对话一致性等指标：在开放问答任务上相对于无记忆基线提高了约20–30%的准确率，同时显著降低了幻觉回答比例。本研究为构建跨语言对话智能体提供了可行的中期方案。


II. 相关工作

长上下文与外部记忆

为了让LLM在长对话中保持记忆，一些研究探索了扩展模型上下文窗口的方法，包括Transformer高效变体（如Longformer、Transformer-XL等）和大窗口版本的预训练模型。然而这些方案会显著增加计算开销，且研究发现即使提供更长的上下文，模型往往无法有效利用其中的信息。因此，另一方向是利用外部工具或数据库实现“无限记忆”。检索增强生成（RAG）就是典型方案：例如Realm、RETRO等模型将对话历史或知识进行向量化存储，使用查询检索相关段落再生成回答。这类方法在开放域问答等任务中取得很好效果。然而，在对话场景中直接应用RAG仍有难点：模型需要决定检索时机并将检索结果正确融入对话，如果提示不当或缺乏示例训练，代理可能不会有效使用检索工具。

层次化记忆架构

受操作系统内存分层启发，MemGPT提出了将LLM扩展为具备虚拟长程记忆的系统。它通过函数调用让LLM智能读写外部存储，在有限窗口内实现“分页”式的无限上下文。MemGPT将记忆划分为主上下文（相当于RAM）和外部上下文（相当于磁盘）两级，当主上下文将满时将部分内容写入外部存储，必要时再读回。这种OS风格的内存管理使代理在长文档分析和多轮对话中表现出色。在MemGPT理念指导下，业界出现了一系列记忆增强型代理框架。例如，MemGPT系列的mem0框架引入了多层记忆池，将短期会话内容与长期知识库相结合。mem0采用消息路由、提示处理器和记忆引擎三模块，将用户消息按会话线程归档，提取关键信息存入结构化记忆对象并建立向量索引，支持随时检索。mem0将记忆划分为不同类型（如事实、事件、意图），针对多线程对话、用户偏好和上下文压缩等提供专门支持。这些设计有效提升了代理对长期多轮对话的一致性和上下文管理能力。另一开源方案Memori提出了双模记忆注入机制：显性短期记忆——在新对话开始时一次性注入近期重要信息；自动长期检索——每轮根据查询内容在全局记忆库中搜索相关记忆片段并注入。这种短期+长期结合的策略与我们架构思想一致。值得注意的是，记忆组件的效果往往依赖于代理能否正确调用。最近有研究比较了多种记忆工具在LoCoMo等基准上的表现。例如，Mem0在LoCoMo问答基准上F1达到68.5%，而另一种文件系统检索方法在同一基准上达到了74.0%。这提示了一个重要事实：代理对工具的有效使用能力往往比工具本身更关键。因此，我们的系统在设计记忆架构的同时，特别注重提示策略和路由规则，使LLM能够充分利用多层记忆提供的信息。

跨语言检索与知识迁移

针对跨语言场景，现有工作主要关注训练多语言LLM和翻译策略。普通多语言LLM在翻译等表层任务上表现尚可，但在需要跨语言推理的知识密集任务上表现不佳。为增强跨语言知识获取，常用的方法包括：利用多语言嵌入技术将不同语言的文本映射到统一语义向量空间，实现查询语言与存储语言不一致时的有效匹配；或者采用中间语言策略，例如先将用户提问翻译成英语，在英文知识库中检索答案再翻译回来。本研究系统选择了前一种方案：使用多语言嵌入模型构建记忆向量索引，使得无论用户用中英文何种语言提问，代理都能检索到相关记忆片段进行回复。这种机制在很大程度上缓解了跨语言知识调用障碍，提升了对话的一致性和连贯性。综上所述，我们的工作建立在上述相关研究基础之上，融合了长短期记忆分层、提示注入、向量检索和多语言处理等技术，旨在打造一个能够跨语言“记忆”用户信息和对话历史的智能体。下文将详细介绍我们的系统架构、实现细节以及实验评估结果。


III. 系统架构

我们提出的系统架构包括三层记忆模块以及相应的提示注入与协同机制，整体如图1所示。主要组成部分如下：
	•	短期记忆（STM）： 用于存储当前会话中最新的重要内容，其生命周期限于单次对话或最近若干轮对话。实现上，STM以结构化YAML格式维护，例如通过要点列表或摘要来表示最近交互的关键信息。短期记忆的内容在每轮对话前都会动态更新，例如提取上一轮用户提供的新事实或澄清的重要细节并写入STM。这使得在生成回复时，模型能够迅速获取“刚刚发生了什么”。由于STM容量有限，一般只保留最近若干轮最相关的信息，以避免提示过长和信息陈旧。
	•	长期记忆（LTM）： 用于持久化存储跨会话的重要信息和知识，包括用户提供的个人资料、过去对话中提及的事实、事件等。LTM采用SQLite数据库结合向量索引实现。我们将每条记忆项（如角色的背景故事或用户喜欢的音乐流派）存储为数据库记录，同时为文本内容生成多语言嵌入向量并建立索引，方便语义检索。LTM的内容跨会话持续存在，模拟了长期记忆。当检测到用户提问涉及过去信息时，系统会查询LTM检索相关记忆片段并注入提示。相比直接将大量历史对话放入提示，我们的LTM方式通过语义检索按需提取，极大减少了提示长度和无关信息干扰。
	•	用户画像（UP）： 用于保存用户的静态偏好、属性和个性化设定等信息，存储格式为JSON文档。UP可以视作特殊的长期记忆，但内容更结构化，例如包含用户的姓名、年龄、语言偏好、专业背景，以及交互中明确提出的偏好（喜欢简洁回答/详细解释、希望对方称呼方式等）。这些信息在每次对话开始时会被提取并注入提示，使模型从一开始就了解用户是谁及其偏好，从而产生个性化响应。UP通常由用户注册信息或长期交互中提炼的偏好构成，并可随着用户行为更新（例如检测到用户多次表示不喜欢某话题时，即更新UP中的偏好字段）。

上述三层记忆在系统中层次分明又紧密配合：STM关注对话短期上下文，LTM涵盖跨会话知识，UP提供个性化先验。为了让LLM有效利用这些记忆，我们设计了提示注入与模型协同机制。其核心思路是：根据当前对话状态和用户请求，在提示中适当位置融合不同层次的记忆内容，从而在不修改模型参数的情况下引导模型基于记忆生成回答。具体机制包括以下步骤：
	1.	消息路由与意图识别： 每当收到用户输入，代理的消息路由模块首先判断消息类型和意图。例如，通过规则或分类模型检测用户提问中是否提及历史事件、人名、偏好关键词等。如果消息包含诸如“之前我告诉过你…？”、“还记得…”这类提示，或提问涉及历史事实，则判定为需要调用长期记忆；如果请求与个人偏好相关（如“帮我推荐一首我可能喜欢的歌”），则需引用用户画像；若是一般对话，则以短期记忆和上下文为主。
	2.	记忆检索： 根据路由判断结果，从相应的记忆库检索信息：对于需要历史事实支持的问题，系统以用户问题或其中的实体为查询在LTM数据库中进行语义搜索，取回若干条相关记忆（如过去的答案或背景知识）；对于涉及用户偏好的请求，从UP中提取相关信息（如用户喜欢的音乐类型）；此外，默认总是获取STM中的最新对话摘要。
	3.	提示构建与注入： 提示处理模块将不同来源的记忆整合到最终提示中。我们采用分段注入策略：首先在系统消息中插入用户画像摘要，例如以JSON格式提供：“用户画像：{…}”；然后在紧随其后的系统消息部分插入长期记忆内容，可采用YAML列表或项目符号方式列出检索到的知识点（例如：“记忆：- 去年用户提到最喜欢的音乐类型是摇滚；- 角色Alice的父亲名为John。”）；接下来注入短期记忆，将最近几轮对话的关键信息（已结构化为YAML列表）放入；最后呈现常规对话提示（包括指令和用户最新提问）。这样构造的提示序列传递给LLM时，系统消息部分包含了回答所需的用户长期信息、对话历史要点以及用户当前请求。值得一提的是，我们在提示中对各类记忆信息进行了格式区分和标注，以帮助模型理解来源。例如，我们会使用前缀标签如“[用户偏好]”标注UP内容，“[历史事实]”标注LTM检索结果，并采用清晰格式（如Markdown列表或YAML块）提供内容，这样模型在生成回答时更容易引用这些内容而非臆测，从而降低幻觉发生率。
	4.	模型生成与记忆更新： LLM收到包含记忆增强的提示后生成回复。在回复生成后，系统解析模型的响应和本轮对话，抽取其中新增的关键信息并更新到STM或LTM。例如，如果用户在本轮提供了新的个人信息（“我换了一份新工作，在谷歌公司。”），系统会将此信息解析后存入LTM的用户信息表，以便后续检索；如果达成了新的约定或情节演进，则将其摘要更新到STM以持续保留在近期上下文中。通过这种循环更新，系统实现了对话的持续学习：交互越多，长期记忆越丰富，智能体对用户和上下文的把握就越准确。

在协同机制中，我们设定了一些路由规则来平衡性能与相关性。例如：每轮默认检索有限数量的LTM条目（通常Top-3最相关结果），以免提示过长影响响应延迟；对于明确的用户偏好请求，优先使用UP信息而不依赖LTM检索；对于跨语言提问，如果当前语言下未检索到结果，系统会将查询自动翻译成另一语言再搜索LTM，以最大程度找到相关记忆。这些规则使得系统在准确性和效率之间取得良好平衡。若记忆库缺乏相关内容，模型则退回到自身知识或直接承认无记忆，从而进一步避免幻觉回答。综上，本系统架构充分利用了短期记忆、长期记忆和用户画像三类记忆，并辅以智能的提示注入和路由策略，使LLM能够像具备“记忆”一样参与对话。相比仅依赖模型自身参数或超长上下文窗口，我们的方法具有可扩展、易于更新、跨会话连续的优势：当有新知识时只需更新数据库，无需重新训练模型；不同用户的记忆相互隔离，个性化信息不污染模型公共权重；敏感数据可本地化存储以增强隐私安全。


IV. 系统实现

在实现层面，我们基于上述架构开发了一个原型对话代理。系统采用模块化设计，主要包含记忆存储模块、嵌入检索模块、提示构建模块和对话管理模块等。后端使用Python语言，借助现有的开源工具提升开发效率。例如，多语言Sentence-BERT用于生成文本嵌入并通过Faiss库构建近似最近邻索引，以支持LTM的快速语义检索。STM和UP直接以文件形式存储（分别为YAML和JSON文件），通过轻量级I/O进行读写更新。SQLite数据库管理长期记忆的存储，包括会话记录表、知识碎片表、用户信息表等，并存储嵌入向量索引的元数据。

我们为LTM实现了add_memory和search_memory两个核心接口：add_memory负责插入新的记忆项（例如当检测到对话中出现新事实时调用此接口存储），并生成其嵌入向量更新索引；search_memory(query)则对输入查询进行编码并在Faiss索引中搜索相关记忆候选，返回相关记忆片段列表。查询流程为：先通过多语言模型将查询编码为向量，然后在索引中进行近邻搜索，再结合关键字过滤和时间戳等元数据进行精排（例如优先同一角色相关的记忆）。STM的更新由对话管理模块自动触发：每轮对话结束后根据预定义规则截取最近的对话摘要写入YAML文件，确保其大小不超过预设阈值（例如最多5条要点）。用户画像UP初始由用户注册信息导入，也可由模型观察用户行为逐步完善，例如用户多次使用同一语言交流时记录其偏好语言。

提示构建与模板： 提示构建模块采用配置模板文件来定义注入格式，以便灵活调整提示结构。我们使用一个YAML模板来组织系统提示的大致结构，运行时将占位符替换为记忆内容。例如模板片段如下：

system_prompt: |
  你是一个智能助理，请参考以下用户信息和历史记忆回答用户问题。
  用户信息:
  {{ user_profile_json }}
  历史记忆:
  {{ relevant_memories_list }}
  当前对话背景:
  {{ recent_summary }}

其中{{ user_profile_json }}等占位符在运行时被替换为UP、LTM、STM提供的实际内容。这样的模板化设计便于根据需要微调提示格式而无需修改代码逻辑。我们尝试了纯文本、JSON和YAML等不同格式，发现对模型而言，使用半结构化格式（如上例，将不同来源的信息分段列出并加以标签）效果更佳。这验证了在提示中显式标注信息来源有助于模型区分哪些内容是记忆而非用户输入，从而降低误读风险。

多语言支持策略： 系统实现中特别考虑了跨语言的一致性。首先，UP字段尽可能存储多语言信息，例如记录语言偏好为代码（“zh”/“en”），用户姓名同时存原文和拼音或翻译，方便在不同语言对话中称呼使用。其次，LTM检索时，如果用户查询使用中文但大部分记忆内容为英文（或反之），系统会对查询进行自动翻译，进行双语言检索，再合并结果以提高召回率。这种查询翻译策略保证了在跨语言提问时不遗漏相关记忆。此外，我们利用语言检测自动判断用户输入语言，并据此选择回复语言，使代理在跨语言对话中表现自然。例如，若用户先用英文交流后来改用中文提问，系统将识别这一转换并用中文回答，同时对应地在记忆检索中切换查询语言。通过这些实现细节，整个系统在多语言环境下保持了对话的流畅性和记忆调用的准确性。

底层模型与接口： 在原型系统中，我们使用OpenAI GPT-4 API作为对话生成模型。GPT-4具备强大的中英文理解和生成能力，是测试我们记忆架构的理想选择。系统通过OpenAI的对话接口发送组装好的消息序列（包含系统消息和用户消息）并获取模型回复。为降低延迟，我们将部分操作并行化，例如在等待模型回复时预先分析下一步可能需要更新的记忆。此外，由于GPT-4调用成本较高，我们还测试了一个开源多语言模型（如MOSS或XGLM）来验证系统的通用性。尽管开源模型在复杂推理上与GPT-4存在差距，但借助我们的记忆增强，在实验场景中仍然可以生成合理的回答。这说明本架构并不依赖于某个特定LLM，其核心思想对不同模型具有普适性。

V. 实验评估

我们通过一系列实验评估所提架构在人物记忆保持、偏好遵循和多轮对话一致性等任务上的有效性。评估分为基于公开数据集的定量测试和基于场景脚本的案例分析两部分。实验设置如下：

A. 实验设置： 定量测试使用LoCoMo长对话记忆基准的问答任务子集。LoCoMo数据包含长达300轮对话及对应的记忆问答，我们选取其中涉及人物关系和事件记忆的50个问答作为测试集，以衡量模型对对话背景事实的记忆准确率。此外，我们设计了一组自定义场景脚本用于评估偏好遵循和一致性。例如，一个场景模拟用户在对话开始时声明语言偏好（如更喜欢中文），随后轮次切换语言提问，检查代理是否遵循用户偏好；另一个场景让用户在前一会话提供个人信息（如宠物名字），在下一会话提及相关内容，看代理是否记住先前信息。我们比较以下四种系统配置（详见表1）：
	•	无记忆：不使用任何STM/LTM/UP机制，代理仅基于自身和最近有限对话生成回答；
	•	仅STM：启用短期记忆摘要注入，但不检索长期记忆或用户画像；
	•	仅LTM：启用长期记忆检索注入，但不包括STM摘要或用户画像；
	•	全记忆（STM+LTM+UP）：启用STM、LTM和UP的完整架构。

对于每种配置，我们记录关键指标：QA-Acc（问答正确率）、Memory-F1（回答内容与真实记忆的F1分数）、Pref-F1（偏好遵循的F1分数）、Hall%（幻觉率，即回答中包含未在记忆或对话中出现的内容比例）、RC%（回忆正确率，即在需要利用记忆的问题中成功调用相关记忆并回答正确的比例），以及平均延迟时间。

A summary of the experimental configurations is provided in Table I.

表1 实验设置（demo）

配置	主/路由模型	版本/日期（示例）	记忆注入	向量检索	环境	平均上下文（tokens）	P95
无记忆	GPT-4o-mini	2025-08	无	无	Xeon/4090	350	1.7
仅STM	GPT-4o-mini	2025-08	YAML 小结	无	同上	650	1.9
仅LTM	GPT-4o	2025-08	LTM Top-k	FAISS	同上	520	2.2
全记忆	路由（Gemini/Claude/GPT-4o）	2025-09	YAML+LTM+UP	FAISS	同上	780	2.4

B. 实验结果： 表2 汇总了不同配置的性能指标。无记忆基线表现最差：QA-Acc仅为54%，Memory-F1为0.35，Pref-F1为0.38，幻觉率达到18%，RC%仅62%。在这种情况下，模型无法有效调用早前信息，回答中经常出现错误或无回答。仅启用STM时，准确率提升至66%，Memory-F1为0.48，Pref-F1为0.50，幻觉率降至14%，RC%为74%。这表明STM对近期信息的摘要帮助了短期连续提问，但对于远程回忆（较久远的对话内容）仍无能为力。仅启用LTM配置则进一步提高：QA-Acc达到71%，Memory-F1为0.63，Pref-F1为0.66，幻觉率降至11%，RC%提升到78%。模型在检索到的长期记忆支持下能够正确回答许多早期对话的提问（如Alice父亲姓名问题），明显减少了凭空猜测。值得注意的是，缺少STM时LTM配置对当前上下文的敏感性较低（例如用户刚刚改变偏好时可能未被及时捕捉），同时在缺少UP时有时会忽略语言偏好（例如检索到正确信息却用非偏好语言回答）。完整配置取得了最好的结果：QA-Acc为84%，相对于基线提高约30个百分点；Memory-F1达0.79，Pref-F1达0.82；幻觉率降至6%，RC%提高到88%。多层记忆的结合让模型能够同时利用近期和历史信息。引入UP之后，偏好遵循显著改善：在偏好场景中，我们观察到无记忆和仅LTM的模型有时会忽略用户的语言偏好，而全记忆模型始终用用户偏好的语言回答问题（如始终以中文回应）。跨轮次一致性方面，全记忆配置的代理在不同会话和轮次保持了较高的一致性。综上所述，多层记忆架构显著提升了问答准确率和记忆相关指标，降低了幻觉率。

表2 LoCoMo子集与场景集结果（demo）（↑越高越好；Hall% 越低越好）

配置	QA-Acc 单跳	QA-Acc 多跳	Memory-F1	Pref-F1	Hall%	RC%	P95 (s)	平均上下文（tokens）
无记忆	54	31	0.35	0.38	18	62	1.7	350
仅STM	66	38	0.48	0.50	14	74	1.9	650
仅LTM	71	52	0.63	0.66	11	78	2.2	520
全记忆	84	68	0.79	0.82	6	88	2.4	780

案例分析： 在偏好遵循场景中，无记忆配置的代理往往无法坚持用户最初声明的偏好。例如，用户在第1轮要求“请用中文回答”，而在第5轮提问时，无记忆模型又切换回英文回答。而我们的系统由于在UP中记录了用户偏好，完整配置下代理始终用中文回应，证明了用户画像的作用。同样，在人物记忆场景中，用户在开始时提供了Alice角色的背景故事，但无记忆或仅STM模型在对话后期已记不清Alice是谁，而启用LTM的模型则能在需要时准确检索并回答（例如，当用户第10轮问“Alice的父亲叫什么？”时，只有配置了LTM的系统答出了正确的名字“John”，而无LTM模型要么回答错误要么无法回答）。此外，我们设计了一致性测试：用户在第1轮陈述“我今年30岁”，第8轮再次被问及年龄，无记忆模型给出了不同的年龄（暴露了前后不一致），而全记忆模型回答仍是30岁，保持了一致性。这些案例直观展示了多层记忆架构对对话质量的改善。

C. 性能开销： 引入记忆机制会带来一定的性能开销。实验显示，无记忆基线的P95响应延迟约为1.7秒，STM配置约1.9秒，LTM配置约2.2秒，而全记忆配置约为2.4秒。也就是说，全记忆配置相比基线增加了约0.5–0.7秒的延迟。尽管如此，这一额外延迟是可接受的，因为它换来了对话正确性和一致性的显著提升。另一方面，全记忆配置的提示长度（平均上下文token数）由基线的350提升到780。虽然提示token数有所增加，但相比于将数千词的完整历史直接拼入提示，我们的方法提示长度仍然较小。综合来看，在明显提升记忆相关性能指标的同时，我们的方法只带来了适度的延迟开销，是一个值得的权衡。

VI. 未来工作

本研究提出的系统为跨语言对话智能体引入了多层次记忆机制并取得了初步成效。未来我们计划从以下几方面进一步改进和扩展：
	•	记忆检索优化： 当前LTM主要依赖语义匹配，有时可能检索出相关度一般的内容。我们考虑结合知识图谱或话题聚类对记忆进行结构化组织，以提高检索精度。另外，可为记忆项添加权重或标签，让系统在生成时识别哪些记忆更重要、哪些可略过，以避免次要信息干扰回答主线。还可以让模型在生成时主动检索细节，例如在回答过程中动态查询记忆，从而进一步提升准确性。
	•	跨语言记忆增强： 为进一步克服跨语言知识屏障，我们考虑引入“双语记忆”机制：关键的长期记忆项同时存储英文和中文表述，或在检索后即时将记忆内容翻译成用户当前语言。这样模型在引用记忆时无需自行翻译，可减少误差。同时，我们计划在多语言LLM上微调提示，使其更善于理解我们的记忆注入格式和跨语言语境。例如，可以通过少量示例教会模型在有记忆提示时依赖记忆而非不可靠的内部联想。
	•	持续学习与记忆衰减： 随着与用户交互的积累，长期记忆库会不断扩大。目前我们采用时间窗和相似度阈值控制记忆数量，未来可探索更智能的“遗忘”策略：例如，根据使用频率和重要度对多年未使用的记忆进行归档或淡出，以模拟人类遗忘无关细节的过程。同时，系统可以引入元学习能力，让代理能从记忆中学习如何改进回答。例如，当模型反复给出用户否定的回答时，可以将这种情况记录为元记忆，从而避免重复同样的错误。
	•	多模态记忆： 本文聚焦于文本对话记忆，未来计划扩展到多模态内容。用户可能在对话中提供图片或语音，我们希望能够记忆和检索视觉或听觉信息。例如，如果用户分享了宠物的照片，系统可以存储该图像的描述或嵌入，并在用户后续提到“我的狗”时检索该图像记忆并使用视觉信息回答。这将要求我们为图像和音频建立跨模态记忆索引，例如利用CLIP等模型将图像和文本映射到共同空间。实现多模态记忆可使代理更全面地支持用户需求。
	•	部署与适应： 最终，我们计划将系统集成到实际应用中（如双语客服机器人）。在部署时需要考虑隐私、安全和性能：敏感记忆可能需要加密存储并进行访问控制，确保只有授权上下文才能调用；对延迟要求更高的场景，可使用缓存和更快速的嵌入模型以降低响应时间。我们也会探索用户反馈机制，例如允许用户纠正代理的记忆（“不，我住在巴黎，不是伦敦”），以提高记忆准确率。我们还希望将系统扩展到更多语言（尤其是资源受限的语言），这可能需要使用适当的多语言模型或翻译管线。

通过上述改进，我们期待构建一个更加智能、记忆更持久且能自适应跨语言需求的对话代理，使其真正胜任长期陪伴式、多语言环境下的智能助手角色。
